from flask import request, jsonify, render_template
from RAG_app1 import app
import openai
import os
import requests
import json
import numpy as np

# OpenAI APIキーの設定
openai.api_key = os.getenv('OPENAI_API_KEY')
# Azure AI Searchの設定
AZURE_SEARCH_ENDPOINT = os.getenv('AZURE_SEARCH_ENDPOINT')
AZURE_SEARCH_API_KEY = os.getenv('AZURE_SEARCH_API_KEY')
AZURE_SEARCH_INDEX_NAME = os.getenv('AZURE_SEARCH_INDEX_NAME')

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/ask', methods=['POST'])
def ask():
    data = request.get_json()
    question = data.get('question')

    if not question:
        return jsonify({'answer': 'No question provided'}), 400

    try:
        # 質問をベクトル化
        question_embedding = openai.Embedding.create(
            input=question,
            model="text-embedding-ada-002"
        )['data'][0]['embedding']
        
        # Azure AI Searchを使用してすべてのドキュメントを取得
        headers = {"Content-Type": "application/json", "api-key": AZURE_SEARCH_API_KEY}
        search_url = f"{AZURE_SEARCH_ENDPOINT}/indexes/{AZURE_SEARCH_INDEX_NAME}/docs/search?api-version=2024-05-01-preview"
        search_payload = {
            "search": "*",
            "select": "content,content_vector",
            "top": 1000,  # 取得するドキュメントの最大数
        }

        search_response = requests.post(search_url, headers=headers, json=search_payload)
        search_results = search_response.json()

        # コサイン類似度を計算
        def cosine_similarity(vec1, vec2):
            vec1 = np.array(vec1)
            vec2 = np.array(vec2)
            return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))

        scored_results = []
        for doc in search_results.get('value', []):
            content_vector = json.loads(doc.get('content_vector', '[]'))
            similarity = cosine_similarity(question_embedding, content_vector)
            scored_results.append((similarity, doc.get('content', '')))

        # 類似度が高い順に並べて、上位2つを取得
        scored_results.sort(reverse=True, key=lambda x: x[0])
        retrieved_texts = "\n".join([result[1] for result in scored_results[:2]])

        # プロンプトを生成
        prompt = f"あなたは優秀な就活生です。面接官からの【質問内容】に対して、下記の【参考情報】を参考にして、簡潔に回答してください。その際に会話として違和感のない、自然な回答を作成してください。\n【参考情報】:\n{retrieved_texts}\n\n【質問内容】:\n{question}"
        # print("question_embedding:", question_embedding)
        #print("Input Question:", question)
        # print("Search Response:", search_response)
        print("retrieved_texts:", retrieved_texts)
        
        #print("prompt:", prompt)

        # OpenAI APIを使用して回答を生成
        response = openai.ChatCompletion.create(
            model="gpt-4-turbo",
            messages=[
                {"role": "system", "content": "日本語で簡潔に答えてください。"},
                {"role": "user", "content": prompt}
            ],
            max_tokens=300
        )

        answer = response.choices[0].message.content.strip()
        return jsonify({'answer': answer})
    except Exception as e:
        return jsonify({'answer': str(e)}), 500

if __name__ == '__main__':
    app.run(debug=True, port=3001)
